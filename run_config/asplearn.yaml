model:
  name: asplearn
  framework: 
  arch: deberta
  scale: base
  threshold: 0.0
  drop_rate: 0.1
  use_adapter: true
  weight: 0.5
  ret_num: 5
  use_cl: -1
  optim_sched: ['AdamW', 'linear']

train:
  epochs: 16
  early_stop: 10
  batch_size: 32
  log_step_rate: 1.0
  learning_rate: 0.00005
  learning_rate_pre: 0.00005
  save_model: 0
  inference: 0
  do_test: false
  wandb: 0

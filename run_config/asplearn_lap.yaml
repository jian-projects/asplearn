model:
  name: asplearn
  framework: 
  arch: deberta
  scale: large
  threshold: 0.0
  drop_rate: 0.1
  use_adapter: true
  weight: 0.3
  ret_num: 3
  use_cl: -1
  optim_sched: ['AdamW', 'linear']

train:
  epochs: 16
  early_stop: 16
  batch_size: 8
  log_step_rate: 1.0
  learning_rate: 0.00008
  learning_rate_pre: 0.00008
  save_model: 0
  inference: 0
  do_test: false
  wandb: 0
